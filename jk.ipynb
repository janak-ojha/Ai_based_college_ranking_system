{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of rows\n",
    "num_rows = 10000\n",
    "\n",
    "# Generating dummy data for each feature\n",
    "data = {\n",
    "    'college_name': [f'College_{i}' for i in range(num_rows)],\n",
    "    'academic_reputation': np.random.uniform(1, 5, num_rows),   # Scale from 1 to 5\n",
    "    'graduation_rates': np.random.uniform(0, 100, num_rows),    # Percentage 0-100\n",
    "    'retention_rates': np.random.uniform(0, 100, num_rows),     # Percentage 0-100\n",
    "    'faculty_resources': np.random.uniform(1, 10, num_rows),    # Scale from 1 to 10\n",
    "    'student_to_faculty_ratio': np.random.uniform(5, 50, num_rows),  # Ratio 5-50\n",
    "    'research_output': np.random.uniform(1, 100, num_rows),     # Scale from 1 to 100\n",
    "    'financial_resources': np.random.uniform(1e6, 1e8, num_rows),   # Scale from 1 million to 100 million\n",
    "    'student_satisfaction': np.random.uniform(1, 5, num_rows),  # Scale from 1 to 5\n",
    "    'employment_outcomes': np.random.uniform(0, 100, num_rows), # Percentage 0-100\n",
    "    # Assuming we have some ground truth scores for training\n",
    "    'true_scores': np.random.uniform(0, 100, num_rows)          # Scale from 0 to 100\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop(columns=['college_name', 'true_scores'])\n",
    "y = df['true_scores']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 25.059787662110686\n",
      "Root Mean Squared Error (RMSE): 29.11387279803502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JANAK RAJ OJHA\\College Ranking System\\college\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Initialize RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on scaled training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Transform the test data using the fitted scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JANAK RAJ OJHA\\College Ranking System\\college\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 10 features, but MinMaxScaler is expecting 9 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m df_features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcollege_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_scores\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 2. Transform features using the fitted scaler\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df_features_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 3. Predict using the trained model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(df_features_scaled)\n",
      "File \u001b[1;32mc:\\Users\\JANAK RAJ OJHA\\College Ranking System\\college\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\JANAK RAJ OJHA\\College Ranking System\\college\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:534\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    530\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    532\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 534\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m X \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    543\u001b[0m X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n",
      "File \u001b[1;32mc:\\Users\\JANAK RAJ OJHA\\College Ranking System\\college\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\JANAK RAJ OJHA\\College Ranking System\\college\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 10 features, but MinMaxScaler is expecting 9 features as input."
     ]
    }
   ],
   "source": [
    "# Assuming 'scaler' and 'model' are already defined and trained as per the previous steps\n",
    "\n",
    "# 1. Drop unnecessary columns for prediction\n",
    "df_features = df.drop(columns=['college_name', 'true_scores'])\n",
    "\n",
    "# 2. Transform features using the fitted scaler\n",
    "df_features_scaled = scaler.transform(df_features)\n",
    "\n",
    "# 3. Predict using the trained model\n",
    "df['predicted_score'] = model.predict(df_features_scaled)\n",
    "\n",
    "# 4. Sort colleges by predicted score in descending order\n",
    "ranked_colleges = df.sort_values(by='predicted_score', ascending=False)\n",
    "\n",
    "# 5. Add a ranking column\n",
    "ranked_colleges['rank'] = range(1, len(ranked_colleges) + 1)\n",
    "\n",
    "# 6. Display the top 10 colleges\n",
    "print(ranked_colleges.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      college_name  academic_reputation  graduation_rates  retention_rates  \\\n",
      "5525  College_5525             1.137507         13.043945         6.144792   \n",
      "5166  College_5166             1.836389          4.734998        72.880620   \n",
      "8347  College_8347             1.131302         77.858185        90.528494   \n",
      "9540  College_9540             1.746932         92.613284        32.329210   \n",
      "1930  College_1930             3.319935         68.984128        71.638656   \n",
      "8092  College_8092             3.343452         12.780584        85.936160   \n",
      "1468  College_1468             4.483014         21.237066        72.887029   \n",
      "1826  College_1826             1.167805         33.971454        52.324424   \n",
      "5154  College_5154             3.705593         50.392901        53.854544   \n",
      "1635  College_1635             1.938568         38.110933         6.684722   \n",
      "\n",
      "      faculty_resources  student_to_faculty_ratio  research_output  \\\n",
      "5525           7.537028                 23.720753        48.125396   \n",
      "5166           3.090881                 38.157596        65.365825   \n",
      "8347           4.786148                 19.400203         9.704997   \n",
      "9540           1.800644                 18.018677        94.826352   \n",
      "1930           1.796685                 39.189681        36.983826   \n",
      "8092           5.875272                 22.717453        96.438788   \n",
      "1468           5.345992                 25.965733        88.505707   \n",
      "1826           8.048920                 24.792788        27.446820   \n",
      "5154           3.051323                 20.917745        47.812579   \n",
      "1635           9.910925                 11.895418        28.530939   \n",
      "\n",
      "      financial_resources  student_satisfaction  employment_outcomes  \\\n",
      "5525         3.031869e+07              3.387087            39.664945   \n",
      "5166         5.217020e+07              1.299526            90.674362   \n",
      "8347         5.447592e+07              4.180853            19.061063   \n",
      "9540         3.591423e+07              3.819969            22.354821   \n",
      "1930         2.719719e+06              3.025298            24.509946   \n",
      "8092         4.605794e+07              1.949054            29.274339   \n",
      "1468         2.260375e+07              3.251505            34.207607   \n",
      "1826         6.362620e+07              2.001745            89.362746   \n",
      "5154         2.547513e+07              3.044518             2.478319   \n",
      "1635         2.118014e+07              1.356010            24.219032   \n",
      "\n",
      "      true_scores  predicted_score  rank  \n",
      "5525    99.843999        90.035078     1  \n",
      "5166    96.741443        88.266048     2  \n",
      "8347    97.272957        86.726642     3  \n",
      "9540    99.539578        86.332851     4  \n",
      "1930    94.872722        86.189959     5  \n",
      "8092    98.106590        85.980289     6  \n",
      "1468    99.408335        85.856271     7  \n",
      "1826    98.709083        85.770064     8  \n",
      "5154    99.084201        85.323587     9  \n",
      "1635    99.548565        85.312891    10  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of rows\n",
    "num_rows = 10000\n",
    "\n",
    "# Generating dummy data for each feature\n",
    "data = {\n",
    "    'college_name': [f'College_{i}' for i in range(num_rows)],\n",
    "    'academic_reputation': np.random.uniform(1, 5, num_rows),   # Scale from 1 to 5\n",
    "    'graduation_rates': np.random.uniform(0, 100, num_rows),    # Percentage 0-100\n",
    "    'retention_rates': np.random.uniform(0, 100, num_rows),     # Percentage 0-100\n",
    "    'faculty_resources': np.random.uniform(1, 10, num_rows),    # Scale from 1 to 10\n",
    "    'student_to_faculty_ratio': np.random.uniform(5, 50, num_rows),  # Ratio 5-50\n",
    "    'research_output': np.random.uniform(1, 100, num_rows),     # Scale from 1 to 100\n",
    "    'financial_resources': np.random.uniform(1e6, 1e8, num_rows),   # Scale from 1 million to 100 million\n",
    "    'student_satisfaction': np.random.uniform(1, 5, num_rows),  # Scale from 1 to 5\n",
    "    'employment_outcomes': np.random.uniform(0, 100, num_rows), # Percentage 0-100\n",
    "    # Assuming we have some ground truth scores for training\n",
    "    'true_scores': np.random.uniform(0, 100, num_rows)          # Scale from 0 to 100\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop(columns=['college_name', 'true_scores'])\n",
    "y = df['true_scores']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform on training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Initialize RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on scaled training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Transform the entire dataset using the fitted scaler\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Predict scores for the entire dataset\n",
    "df['predicted_score'] = model.predict(X_scaled)\n",
    "\n",
    "# Sort colleges by predicted score in descending order\n",
    "ranked_colleges = df.sort_values(by='predicted_score', ascending=False)\n",
    "\n",
    "# Add a ranking column\n",
    "ranked_colleges['rank'] = range(1, len(ranked_colleges) + 1)\n",
    "\n",
    "# Display the top 10 colleges\n",
    "print(ranked_colleges.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      college_name  rank\n",
      "5525  College_5525     1\n",
      "5166  College_5166     2\n",
      "8347  College_8347     3\n",
      "9540  College_9540     4\n",
      "1930  College_1930     5\n",
      "8092  College_8092     6\n",
      "1468  College_1468     7\n",
      "1826  College_1826     8\n",
      "5154  College_5154     9\n",
      "1635  College_1635    10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of rows\n",
    "num_rows = 10000\n",
    "\n",
    "# Generating dummy data for each feature\n",
    "data = {\n",
    "    'college_name': [f'College_{i}' for i in range(num_rows)],\n",
    "    'academic_reputation': np.random.uniform(1, 5, num_rows),   # Scale from 1 to 5\n",
    "    'graduation_rates': np.random.uniform(0, 100, num_rows),    # Percentage 0-100\n",
    "    'retention_rates': np.random.uniform(0, 100, num_rows),     # Percentage 0-100\n",
    "    'faculty_resources': np.random.uniform(1, 10, num_rows),    # Scale from 1 to 10\n",
    "    'student_to_faculty_ratio': np.random.uniform(5, 50, num_rows),  # Ratio 5-50\n",
    "    'research_output': np.random.uniform(1, 100, num_rows),     # Scale from 1 to 100\n",
    "    'financial_resources': np.random.uniform(1e6, 1e8, num_rows),   # Scale from 1 million to 100 million\n",
    "    'student_satisfaction': np.random.uniform(1, 5, num_rows),  # Scale from 1 to 5\n",
    "    'employment_outcomes': np.random.uniform(0, 100, num_rows), # Percentage 0-100\n",
    "    # Assuming we have some ground truth scores for training\n",
    "    'true_scores': np.random.uniform(0, 100, num_rows)          # Scale from 0 to 100\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop(columns=['college_name', 'true_scores'])\n",
    "y = df['true_scores']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform on training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Initialize RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on scaled training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Transform the entire dataset using the fitted scaler\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Predict scores for the entire dataset\n",
    "df['predicted_score'] = model.predict(X_scaled)\n",
    "\n",
    "# Sort colleges by predicted score in descending order\n",
    "ranked_colleges = df.sort_values(by='predicted_score', ascending=False)\n",
    "\n",
    "# Add a ranking column\n",
    "ranked_colleges['rank'] = range(1, len(ranked_colleges) + 1)\n",
    "\n",
    "# Display only college_name and rank for the top 10 colleges\n",
    "top_colleges = ranked_colleges[['college_name', 'rank']].head(10)\n",
    "print(top_colleges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      college_name  rank\n",
      "5525  College_5525     1\n",
      "5166  College_5166     2\n",
      "8347  College_8347     3\n",
      "9540  College_9540     4\n",
      "1930  College_1930     5\n",
      "8092  College_8092     6\n",
      "1468  College_1468     7\n",
      "1826  College_1826     8\n",
      "5154  College_5154     9\n",
      "1635  College_1635    10\n",
      "\n",
      "Top 10 Colleges in Your City (Predicted):\n",
      "\n",
      "     college_name  rank\n",
      "2   New_College_3     1\n",
      "4   New_College_5     2\n",
      "3   New_College_4     3\n",
      "5   New_College_6     4\n",
      "6   New_College_7     5\n",
      "9  New_College_10     6\n",
      "8   New_College_9     7\n",
      "1   New_College_2     8\n",
      "7   New_College_8     9\n",
      "0   New_College_1    10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of rows\n",
    "num_rows = 10000\n",
    "\n",
    "# Generating dummy data for each feature\n",
    "data = {\n",
    "    'college_name': [f'College_{i}' for i in range(num_rows)],\n",
    "    'academic_reputation': np.random.uniform(1, 5, num_rows),   # Scale from 1 to 5\n",
    "    'graduation_rates': np.random.uniform(0, 100, num_rows),    # Percentage 0-100\n",
    "    'retention_rates': np.random.uniform(0, 100, num_rows),     # Percentage 0-100\n",
    "    'faculty_resources': np.random.uniform(1, 10, num_rows),    # Scale from 1 to 10\n",
    "    'student_to_faculty_ratio': np.random.uniform(5, 50, num_rows),  # Ratio 5-50\n",
    "    'research_output': np.random.uniform(1, 100, num_rows),     # Scale from 1 to 100\n",
    "    'financial_resources': np.random.uniform(1e6, 1e8, num_rows),   # Scale from 1 million to 100 million\n",
    "    'student_satisfaction': np.random.uniform(1, 5, num_rows),  # Scale from 1 to 5\n",
    "    'employment_outcomes': np.random.uniform(0, 100, num_rows), # Percentage 0-100\n",
    "    # Assuming we have some ground truth scores for training\n",
    "    'true_scores': np.random.uniform(0, 100, num_rows)          # Scale from 0 to 100\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop(columns=['college_name', 'true_scores'])\n",
    "y = df['true_scores']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform on training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Initialize RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on scaled training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Transform the entire dataset using the fitted scaler\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Predict scores for the entire dataset\n",
    "df['predicted_score'] = model.predict(X_scaled)\n",
    "\n",
    "# Sort colleges by predicted score in descending order\n",
    "ranked_colleges = df.sort_values(by='predicted_score', ascending=False)\n",
    "\n",
    "# Add a ranking column\n",
    "ranked_colleges['rank'] = range(1, len(ranked_colleges) + 1)\n",
    "\n",
    "# Display only college_name and rank for the top 10 colleges\n",
    "top_colleges = ranked_colleges[['college_name', 'rank']].head(10)\n",
    "print(top_colleges)\n",
    "\n",
    "# Testing new data (10 colleges in your city)\n",
    "new_data = {\n",
    "    'college_name': ['New_College_1', 'New_College_2', 'New_College_3', 'New_College_4', 'New_College_5',\n",
    "                     'New_College_6', 'New_College_7', 'New_College_8', 'New_College_9', 'New_College_10'],\n",
    "    'academic_reputation': np.random.uniform(1, 5, 10),   # Scale from 1 to 5\n",
    "    'graduation_rates': np.random.uniform(0, 100, 10),    # Percentage 0-100\n",
    "    'retention_rates': np.random.uniform(0, 100, 10),     # Percentage 0-100\n",
    "    'faculty_resources': np.random.uniform(1, 10, 10),    # Scale from 1 to 10\n",
    "    'student_to_faculty_ratio': np.random.uniform(5, 50, 10),  # Ratio 5-50\n",
    "    'research_output': np.random.uniform(1, 100, 10),     # Scale from 1 to 100\n",
    "    'financial_resources': np.random.uniform(1e6, 1e8, 10),   # Scale from 1 million to 100 million\n",
    "    'student_satisfaction': np.random.uniform(1, 5, 10),  # Scale from 1 to 5\n",
    "    'employment_outcomes': np.random.uniform(0, 100, 10)   # Percentage 0-100\n",
    "}\n",
    "\n",
    "# Create DataFrame for new data\n",
    "df_new = pd.DataFrame(new_data)\n",
    "\n",
    "# Prepare new data for prediction (drop 'college_name')\n",
    "X_new = df_new.drop(columns=['college_name'])\n",
    "\n",
    "# Transform new data using the fitted scaler\n",
    "X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "# Predict scores for new data\n",
    "df_new['predicted_score'] = model.predict(X_new_scaled)\n",
    "\n",
    "# Sort new colleges by predicted score in descending order\n",
    "ranked_new_colleges = df_new.sort_values(by='predicted_score', ascending=False)\n",
    "\n",
    "# Add a ranking column for new colleges\n",
    "ranked_new_colleges['rank'] = range(1, len(ranked_new_colleges) + 1)\n",
    "\n",
    "# Display only college_name and rank for the new colleges\n",
    "print(\"\\nTop 10 Colleges in Your City (Predicted):\\n\")\n",
    "print(ranked_new_colleges[['college_name', 'rank']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to CSV successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already defined 'data' and created 'df' as in your example\n",
    "\n",
    "# Define the number of rows\n",
    "num_rows = 10000\n",
    "\n",
    "# Generating dummy data for each feature\n",
    "data = {\n",
    "    'college_name': [f'College_{i}' for i in range(num_rows)],\n",
    "    'academic_reputation': np.random.uniform(1, 5, num_rows),   # Scale from 1 to 5\n",
    "    'graduation_rates': np.random.uniform(0, 100, num_rows),    # Percentage 0-100\n",
    "    'retention_rates': np.random.uniform(0, 100, num_rows),     # Percentage 0-100\n",
    "    'faculty_resources': np.random.uniform(1, 10, num_rows),    # Scale from 1 to 10\n",
    "    'student_to_faculty_ratio': np.random.uniform(5, 50, num_rows),  # Ratio 5-50\n",
    "    'research_output': np.random.uniform(1, 100, num_rows),     # Scale from 1 to 100\n",
    "    'financial_resources': np.random.uniform(1e6, 1e8, num_rows),   # Scale from 1 million to 100 million\n",
    "    'student_satisfaction': np.random.uniform(1, 5, num_rows),  # Scale from 1 to 5\n",
    "    'employment_outcomes': np.random.uniform(0, 100, num_rows), # Percentage 0-100\n",
    "    'true_scores': np.random.uniform(0, 100, num_rows)          # Scale from 0 to 100\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "df.to_csv('dummy_college_data.csv', index=False)\n",
    "\n",
    "print(\"DataFrame saved to CSV successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to CSV successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of rows\n",
    "num_rows = 10  # Adjusted to 10 for 10 colleges\n",
    "\n",
    "# Generating dummy data for each feature\n",
    "data = {\n",
    "    'college_name': [f'College_{i}' for i in range(num_rows)],\n",
    "    'academic_reputation': np.random.uniform(1, 5, num_rows),   # Scale from 1 to 5\n",
    "    'graduation_rates': np.random.uniform(0, 100, num_rows),    # Percentage 0-100\n",
    "    'retention_rates': np.random.uniform(0, 100, num_rows),     # Percentage 0-100\n",
    "    'faculty_resources': np.random.uniform(1, 10, num_rows),    # Scale from 1 to 10\n",
    "    'student_to_faculty_ratio': np.random.uniform(5, 50, num_rows),  # Ratio 5-50\n",
    "    'research_output': np.random.uniform(1, 100, num_rows),     # Scale from 1 to 100\n",
    "    'financial_resources': np.random.uniform(1e6, 1e8, num_rows),   # Scale from 1 million to 100 million\n",
    "    'student_satisfaction': np.random.uniform(1, 5, num_rows),  # Scale from 1 to 5\n",
    "    'employment_outcomes': np.random.uniform(0, 100, num_rows), # Percentage 0-100\n",
    "    'true_scores': np.random.uniform(0, 100, num_rows)          # Scale from 0 to 100\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "df.to_csv('dummy_college_data_10.csv', index=False)\n",
    "\n",
    "print(\"DataFrame saved to CSV successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame saved to CSV successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define new data dictionary\n",
    "new_data = {\n",
    "    'college_name': ['New_College_1', 'New_College_2', 'New_College_3', 'New_College_4', 'New_College_5',\n",
    "                     'New_College_6', 'New_College_7', 'New_College_8', 'New_College_9', 'New_College_10'],\n",
    "    'academic_reputation': np.random.uniform(1, 5, 10),   # Scale from 1 to 5\n",
    "    'graduation_rates': np.random.uniform(0, 100, 10),    # Percentage 0-100\n",
    "    'retention_rates': np.random.uniform(0, 100, 10),     # Percentage 0-100\n",
    "    'faculty_resources': np.random.uniform(1, 10, 10),    # Scale from 1 to 10\n",
    "    'student_to_faculty_ratio': np.random.uniform(5, 50, 10),  # Ratio 5-50\n",
    "    'research_output': np.random.uniform(1, 100, 10),     # Scale from 1 to 100\n",
    "    'financial_resources': np.random.uniform(1e6, 1e8, 10),   # Scale from 1 million to 100 million\n",
    "    'student_satisfaction': np.random.uniform(1, 5, 10),  # Scale from 1 to 5\n",
    "    'employment_outcomes': np.random.uniform(0, 100, 10)   # Percentage 0-100\n",
    "}\n",
    "\n",
    "# Create DataFrame for new data\n",
    "df_new = pd.DataFrame(new_data)\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "df_new.to_csv('new_college_data.csv', index=False)\n",
    "\n",
    "print(\"New DataFrame saved to CSV successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame saved to CSV successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define new data dictionary including true_scores\n",
    "new_data = {\n",
    "    'college_name': ['New_College_1', 'New_College_2', 'New_College_3', 'New_College_4', 'New_College_5',\n",
    "                     'New_College_6', 'New_College_7', 'New_College_8', 'New_College_9', 'New_College_10'],\n",
    "    'academic_reputation': np.random.uniform(1, 5, 10),   # Scale from 1 to 5\n",
    "    'graduation_rates': np.random.uniform(0, 100, 10),    # Percentage 0-100\n",
    "    'retention_rates': np.random.uniform(0, 100, 10),     # Percentage 0-100\n",
    "    'faculty_resources': np.random.uniform(1, 10, 10),    # Scale from 1 to 10\n",
    "    'student_to_faculty_ratio': np.random.uniform(5, 50, 10),  # Ratio 5-50\n",
    "    'research_output': np.random.uniform(1, 100, 10),     # Scale from 1 to 100\n",
    "    'financial_resources': np.random.uniform(1e6, 1e8, 10),   # Scale from 1 million to 100 million\n",
    "    'student_satisfaction': np.random.uniform(1, 5, 10),  # Scale from 1 to 5\n",
    "    'employment_outcomes': np.random.uniform(0, 100, 10),  # Percentage 0-100\n",
    "    'true_scores': np.random.uniform(0, 100, 10)          # Scale from 0 to 100\n",
    "}\n",
    "\n",
    "# Create DataFrame for new data\n",
    "df_new = pd.DataFrame(new_data)\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "df_new.to_csv('utu.csv', index=False)\n",
    "\n",
    "print(\"New DataFrame saved to CSV successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "college",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
